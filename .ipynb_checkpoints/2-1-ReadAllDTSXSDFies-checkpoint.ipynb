{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the general DTS and save the taxonomy schema to PostgreSQL\n",
    "from hibachiPostgreSQL import ReadAllGeneralDTSPathesInPostgre # For getting file general DTS pathes\n",
    "from hibachixbrl import HibachiXmlElement, HibachiETtree\n",
    "import pandas as pd\n",
    "import sys\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting to the PostgreSQL database...\n",
      "Connection is closed.\n"
     ]
    }
   ],
   "source": [
    "# Get all the general DTS file pathes saved in PostgreSQL \n",
    "df_DTSPathes = ReadAllGeneralDTSPathesInPostgre.generalDTSPathes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readXSDinGeneralDTS(df_generalDTS):\n",
    "    ''' Get all the TaxonomySchema, Linkbase, FootnoteLink, Roletype classes in .xsd file.'''\n",
    "\n",
    "    # Dataframes for TaxonomySchema, Linkbase, RoleTypes\n",
    "    df_TaxonomySchema = pd.DataFrame(columns=['filepath','TaxonomySchemaObj'])\n",
    "    df_Linkbases      = pd.DataFrame(columns=['filepath','linkbaseObj'])\n",
    "    df_RoleTypes      = pd.DataFrame(columns=['filepath','roletypeObj'])    \n",
    "\n",
    "    for CurrentPathName in df_generalDTS['filepath']:\n",
    "        #Get the extention of the current file\n",
    "        CurrentFileName = os.path.split(CurrentPathName)[1]\n",
    "        CurrentFileExtension = os.path.splitext(CurrentPathName)[1] \n",
    "        if CurrentFileExtension == '.xsd':\n",
    "                   \n",
    "            try:\n",
    "                root_ElementTree = HibachiETtree.etree_parse_remove_NS(CurrentPathName)\n",
    "                if root_ElementTree != None:\n",
    "                    \n",
    "                    # print the current file name\n",
    "                    # print('Reading', CurrentFileName ,' ...')\n",
    "                    # List of tags for taxonomy schema, linkbase and roleType/Refs\n",
    "                    schema_tags = ['import','include','schemaRef','linkbaseRef','roleRef', 'arcroleRef']\n",
    "                    linkbase_tags = ['linkbase','schema']\n",
    "                    search_tags = schema_tags + linkbase_tags\n",
    "                    \n",
    "                    # Search elements with the tags listed above and corresponding create instances\n",
    "                    for empty_Var, search_tagName in enumerate(search_tags):\n",
    "                        for schema_ElementTree in root_ElementTree.iter(search_tagName):\n",
    "                            # Taxonomy Schema\n",
    "                            if search_tagName in schema_tags:\n",
    "                                df_TaxonomySchema = df_TaxonomySchema.append(\\\n",
    "                                    {'filepath':CurrentPathName,\\\n",
    "                                     'TaxonomySchemaObj':HibachiXmlElement.TaxonomySchema(CurrentFileName, schema_ElementTree)}\\\n",
    "                                    ,ignore_index=True\n",
    "                                )\n",
    "                                \n",
    "                            # 5.1.2 <linkbase>\n",
    "                            elif search_tagName == 'linkbase':\n",
    "                                df_Linkbases = df_Linkbases.append(\\\n",
    "                                    {'filepath':CurrentPathName,\\\n",
    "                                     'linkbaseObj':HibachiXmlElement.Linkbase(CurrentFileName, schema_ElementTree)}\\\n",
    "                                    ,ignore_index=True\n",
    "                                )\n",
    "                                \n",
    "                            # 5.1.3 <roleType>, 5.1.4 <arcroleType>\n",
    "#                             5.1.3 Defining custom role types - the <roleType> element\n",
    "#                             The <roleType> element MUST be located among the set of nodes identified by the [XPath 1.0] path \"//xsd:schema/xsd:annotation/xsd:appinfo/*\".\n",
    "#                             The value of the @roleURI attribute identifies the @xlink:role attribute value that is being defined.\n",
    "#                             5.1.4 Defining custom arc role types - the arcroleType element\n",
    "#                             The <arcroleType> element MUST be among the set of nodes identified by the [XPath 1.0] path \"//xsd:schema/xsd:annotation/xsd:appinfo/*\".\n",
    "#                             The value of the @arcroleURI identifies the @xlink:arcrole attribute value that is being defined.\n",
    "\n",
    "                            elif search_tagName == 'schema':\n",
    "                                for annotation_ElementTree in schema_ElementTree.findall('annotation'):\n",
    "                                    for appinfo_ElementTree in annotation_ElementTree.findall('appinfo'):\n",
    "                                        \n",
    "                                        roleType_Tags = ['roleType','arcroleType']\n",
    "                                        for empty_Var, temp_tagName in enumerate(roleType_Tags):\n",
    "                                            for temp_roleType_ElementTree in appinfo_ElementTree.findall(temp_tagName): #\n",
    "                                                df_RoleTypes = df_RoleTypes.append(\\\n",
    "                                                    {'filepath':CurrentPathName,\\\n",
    "                                                     'roletypeObj':HibachiXmlElement.Roletype(CurrentFileName, temp_roleType_ElementTree)}\\\n",
    "                                                    ,ignore_index=True\n",
    "                                                )\n",
    "                                                \n",
    "                                        roleRef_Tags = ['roleRef', 'arcroleRef']\n",
    "                                        for empty_Var, temp_tagName in enumerate(roleRef_Tags):\n",
    "                                            for temp_roleRef_ElementTree in appinfo_ElementTree.findall(temp_tagName):\n",
    "                                                df_TaxonomySchema = df_TaxonomySchema.append(\\\n",
    "                                                    {'filepath':CurrentPathName,\\\n",
    "                                                     'TaxonomySchemaObj':HibachiXmlElement.TaxonomySchema(CurrentFileName, schema_ElementTree)}\\\n",
    "                                                    ,ignore_index=True\n",
    "                                                )\n",
    "                            else:\n",
    "                                print('Tag is:',search_tagName, ' . Ignored.')\n",
    "                else:\n",
    "                    print('No root element')\n",
    "\n",
    "            except:\n",
    "                print ('Error in reading:', CurrentPathName, sys.exc_info()[0], sys.exc_info()[1])\n",
    "    return df_TaxonomySchema, df_Linkbases, df_RoleTypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the function\n",
    "df_Taxonomy, df_Linkbase, df_RoleType = readXSDinGeneralDTS(df_generalDTS=df_DTSPathes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unfold the Taxonomy Schema instace to Series and put it into dataframe\n",
    "# Concate the unfolded dataframe to the original dataframe\n",
    "# df_TaxonomyForSQL = df_Taxonomy['TaxonomySchemaObj'].apply(lambda x: pd.Series(x.__dict__))\n",
    "# df_RoleTypeForSQL = df_RoleType['roletypeObj'].apply(lambda x: pd.Series(x.__dict__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Format the dataframe to save it in SQL\n",
    "df_TaxonomyForSQL = pd.concat([df_Taxonomy['filepath'],df_Taxonomy['TaxonomySchemaObj'].apply(lambda x: pd.Series(x.__dict__))], axis=1)\n",
    "#df_RoleTypeForSQL = pd.concat([df_RoleType['filepath'],df_RoleType['roletypeObj'].apply(lambda x: pd.Series(x.__dict__))],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the dataframe containing general DTS to PostgreSQL\n",
    "# Connect to PostgreSQL\n",
    "from sqlalchemy import create_engine\n",
    "from config import config\n",
    "\n",
    "try:\n",
    "    params = config()\n",
    "    engine = create_engine('postgresql://{user}:{password}@{host}:{port}/{database}'.format(**params))\n",
    "\n",
    "    # Save the dataframe to PostgreSQL (make sure to type table names in lower cases)\n",
    "    df_TaxonomyForSQL.to_sql('taxonomyschema_generaldts', con=engine, if_exists='replace', index=False)\n",
    "#     df_RoleTypeForSQL.to_sql('roletype_generaldts', con=engine, if_exists='replace', index=False)\n",
    "except:\n",
    "    print ('Error:', sys.exc_info()[0], sys.exc_info()[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
